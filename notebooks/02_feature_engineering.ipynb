{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 â€” Feature Engineering\n",
    "\n",
    "This notebook computes technical indicators, fundamental features, and sentiment scores for the selected stocks. We will:\n",
    "1. Load historical price data\n",
    "2. Engineer technical features (RSI, MACD, Bollinger Bands, etc.)\n",
    "3. Visualize technical indicators\n",
    "4. Create cross-sectional feature matrix\n",
    "5. Compute sentiment scores\n",
    "6. Combine all features into a unified dataset\n",
    "7. Analyze feature correlations\n",
    "8. Save engineered features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_loader import get_stock_data, fetch_multiple_stocks\n",
    "from feature_engineering import engineer_features, create_feature_matrix\n",
    "from sentiment import compute_batch_sentiment\n",
    "\n",
    "# Display and plot settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from previous notebook or from saved parquet\n",
    "try:\n",
    "    price_matrix = pd.read_parquet('../data/raw/price_matrix.parquet')\n",
    "    returns_matrix = pd.read_parquet('../data/raw/returns_matrix.parquet')\n",
    "    fundamentals_df = pd.read_parquet('../data/raw/fundamentals.parquet')\n",
    "    selected_tickers = pd.read_csv('../data/raw/selected_tickers.csv')['ticker'].tolist()\n",
    "    print(\"Data loaded successfully from parquet files\")\nexcept Exception as e:\n",
    "    print(f\"Error loading parquet files: {e}\")\n",
    "    print(\"Falling back to data_loader functions...\")\n",
    "    selected_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN']\n",
    "    stock_data = fetch_multiple_stocks(selected_tickers, period='2y')\n",
    "\n",
    "print(f\"\\nLoaded data for {len(selected_tickers)} tickers\")\n",
    "print(f\"Price matrix shape: {price_matrix.shape}\")\n",
    "print(f\"Returns matrix shape: {returns_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Engineer Technical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one sample stock for demonstration\n",
    "sample_ticker = 'AAPL'\n",
    "sample_stock_data = stock_data[sample_ticker] if isinstance(stock_data, dict) else price_matrix[[sample_ticker]].to_frame()\n",
    "\n",
    "# Engineer technical features\n",
    "engineered_data = engineer_features(sample_stock_data)\n",
    "\n",
    "print(f\"Engineered features for {sample_ticker}:\")\n",
    "print(f\"Shape: {engineered_data.shape}\")\n",
    "print(f\"\\nColumns: {engineered_data.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "engineered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for technical indicators\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Price and Bollinger Bands\n",
    "axes[0].plot(engineered_data.index, engineered_data['Close'], label='Close Price', linewidth=2)\n",
    "if 'BB_High' in engineered_data.columns and 'BB_Low' in engineered_data.columns:\n",
    "    axes[0].fill_between(engineered_data.index, engineered_data['BB_High'], \n",
    "                          engineered_data['BB_Low'], alpha=0.2, label='Bollinger Bands')\n",
    "axes[0].set_title(f'{sample_ticker} Price with Bollinger Bands', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: RSI\n",
    "if 'RSI' in engineered_data.columns:\n",
    "    axes[1].plot(engineered_data.index, engineered_data['RSI'], label='RSI', linewidth=2, color='orange')\n",
    "    axes[1].axhline(y=70, color='r', linestyle='--', alpha=0.5, label='Overbought (70)')\n",
    "    axes[1].axhline(y=30, color='g', linestyle='--', alpha=0.5, label='Oversold (30)')\n",
    "    axes[1].set_title('Relative Strength Index (RSI)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('RSI')\n",
    "    axes[1].set_ylim([0, 100])\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: MACD\n",
    "if 'MACD' in engineered_data.columns:\n",
    "    axes[2].plot(engineered_data.index, engineered_data['MACD'], label='MACD', linewidth=2, color='purple')\n",
    "    if 'MACD_Signal' in engineered_data.columns:\n",
    "        axes[2].plot(engineered_data.index, engineered_data['MACD_Signal'], label='Signal Line', linewidth=2, color='red')\n",
    "    axes[2].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    axes[2].set_title('MACD', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('MACD')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Cross-Sectional Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix for all selected stocks\n",
    "feature_matrix = create_feature_matrix(stock_data if isinstance(stock_data, dict) else {t: price_matrix[[t]] for t in selected_tickers})\n",
    "\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(feature_matrix.dtypes)\n",
    "print(f\"\\nFeature matrix info:\")\n",
    "print(feature_matrix.info())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sentiment for sample tickers\n",
    "sample_sentiment_tickers = selected_tickers[:10]  # Sentiment analysis for first 10 stocks\n",
    "\n",
    "try:\n",
    "    sentiment_scores = compute_batch_sentiment(sample_sentiment_tickers)\n",
    "    print(f\"Sentiment scores computed for {len(sentiment_scores)} tickers\")\n",
    "    print(f\"\\nSentiment Scores:\")\n",
    "    print(sentiment_scores)\nexcept Exception as e:\n",
    "    print(f\"Note: Sentiment analysis not available: {e}\")\n",
    "    print(\"Creating dummy sentiment data for demonstration...\")\n",
    "    sentiment_scores = pd.DataFrame({\n",
    "        'ticker': sample_sentiment_tickers,\n",
    "        'sentiment': np.random.randn(len(sample_sentiment_tickers)),\n",
    "        'news_count': np.random.randint(5, 50, len(sample_sentiment_tickers))\n",
    "    })\n",
    "    print(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge feature_matrix with fundamentals\n",
    "combined_features = feature_matrix.copy()\n",
    "\n",
    "# Add fundamentals data\n",
    "if 'fundamentals_df' in locals():\n",
    "    # Align indices if needed\n",
    "    fundamentals_indexed = fundamentals_df.reset_index().set_index('ticker')\n",
    "    for col in fundamentals_indexed.columns:\n",
    "        combined_features[f'fund_{col}'] = combined_features.index.map(\n",
    "            fundamentals_indexed[col].to_dict()\n",
    "        )\n",
    "\n",
    "# Add sentiment data\n",
    "if 'sentiment_scores' in locals():\n",
    "    sentiment_indexed = sentiment_scores.set_index('ticker')\n",
    "    for col in sentiment_indexed.columns:\n",
    "        combined_features[f'sent_{col}'] = combined_features.index.map(\n",
    "            sentiment_indexed[col].to_dict()\n",
    "        )\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"Missing values before handling:\")\n",
    "print(combined_features.isnull().sum().sum())\n",
    "\n",
    "# Fill missing values\n",
    "combined_features = combined_features.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "print(f\"\\nCombined feature matrix shape: {combined_features.shape}\")\n",
    "print(f\"Total columns: {len(combined_features.columns)}\")\n",
    "print(f\"Missing values after handling: {combined_features.isnull().sum().sum()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "combined_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_features = combined_features.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_matrix = numeric_features.corr()\n",
    "\n",
    "# Plot correlation heatmap for top features by variance\n",
    "top_n = 20\n",
    "top_features = numeric_features.var().nlargest(top_n).index\n",
    "top_correlation = correlation_matrix.loc[top_features, top_features]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(top_correlation, cmap='coolwarm', center=0, \n",
    "            square=True, annot=True, fmt='.2f', cbar_kws={'label': 'Correlation'})\n",
    "plt.title(f'Top {top_n} Features Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "print(f\"\\nHighly correlated feature pairs (> 0.8):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            print(f\"{correlation_matrix.columns[i]} <-> {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create processed data directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save combined features\n",
    "combined_features.to_parquet('../data/processed/feature_matrix.parquet')\n",
    "\n",
    "# Save feature metadata\n",
    "feature_metadata = pd.DataFrame({\n",
    "    'feature': combined_features.columns,\n",
    "    'data_type': combined_features.dtypes.astype(str),\n",
    "    'missing_pct': (combined_features.isnull().sum() / len(combined_features) * 100).values\n",
    "})\n",
    "feature_metadata.to_csv('../data/processed/feature_metadata.csv', index=False)\n",
    "\n",
    "print(\"Features saved successfully!\")\n",
    "print(f\"  - feature_matrix.parquet ({combined_features.shape})\")\n",
    "print(f\"  - feature_metadata.csv (metadata for {len(feature_metadata)} features)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
